{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "119e2660-dde8-4d97-8d52-effa3610c6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa0e39a2-82e3-4fe9-8a4d-5509940aeb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://cloudml-demo-lcm/SO_ml_tags_avocado_188k_v2.csv...\n",
      "\\ [1 files][276.7 MiB/276.7 MiB]                                                \n",
      "Operation completed over 1 objects/276.7 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp 'gs://cloudml-demo-lcm/SO_ml_tags_avocado_188k_v2.csv' ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ee8a26a-db06-4fc9-87c3-4aae0c5446c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join('.', 'SO_ml_tags_avocado_188k_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10b3086d-de68-467d-a696-3019a384e7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('SO_ml_tags_avocado_188k_v2.csv', names=['tags', 'original_text,', 'text'], header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6b5848f-38ae-406f-8bab-e78b680b8d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>original_text,</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>matplotlib,pandas</td>\n",
       "      <td>python,matplotlib,pandas</td>\n",
       "      <td>setting xticks and yticks for scatter plot mat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scikitlearn,keras</td>\n",
       "      <td>python,numpy,scikit-learn,keras,grid-search</td>\n",
       "      <td>gridseachcv - valueerror: found input variable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>matplotlib,scikitlearn</td>\n",
       "      <td>python,numpy,matplotlib,scikit-learn,nmf</td>\n",
       "      <td>non negative matrix factorisation in python on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pandas,tensorflow</td>\n",
       "      <td>python,pandas,tensorflow,time-series</td>\n",
       "      <td>avocado equivalent to avocado.dataframe.resamp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>matplotlib,pandas</td>\n",
       "      <td>python,matplotlib,plot,pandas</td>\n",
       "      <td>how to plot on avocado python i have a data fr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     tags                               original_text,  \\\n",
       "0       matplotlib,pandas                     python,matplotlib,pandas   \n",
       "1       scikitlearn,keras  python,numpy,scikit-learn,keras,grid-search   \n",
       "2  matplotlib,scikitlearn     python,numpy,matplotlib,scikit-learn,nmf   \n",
       "3       pandas,tensorflow         python,pandas,tensorflow,time-series   \n",
       "4       matplotlib,pandas                python,matplotlib,plot,pandas   \n",
       "\n",
       "                                                text  \n",
       "0  setting xticks and yticks for scatter plot mat...  \n",
       "1  gridseachcv - valueerror: found input variable...  \n",
       "2  non negative matrix factorisation in python on...  \n",
       "3  avocado equivalent to avocado.dataframe.resamp...  \n",
       "4  how to plot on avocado python i have a data fr...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09234265-2c81-4493-a139-13899c4ba9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a290162-bcde-496b-a7fd-277a40cc1c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['original_text,'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448374ec-3610-44ad-8d87-533747b74953",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8f8b354-c660-4d12-a365-114a8acac6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64533</th>\n",
       "      <td>pandas</td>\n",
       "      <td>selecting specific rows in df based on 2 colum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124736</th>\n",
       "      <td>matplotlib</td>\n",
       "      <td>avocado: border line drawn on only the first b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184298</th>\n",
       "      <td>pandas,matplotlib</td>\n",
       "      <td>avocado dataframe groupby plot i have a datafr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21765</th>\n",
       "      <td>pandas</td>\n",
       "      <td>how to set avocado dataframe multiindex in con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7607</th>\n",
       "      <td>keras</td>\n",
       "      <td>what's the difference between lstm() and lstmc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     tags                                               text\n",
       "64533              pandas  selecting specific rows in df based on 2 colum...\n",
       "124736         matplotlib  avocado: border line drawn on only the first b...\n",
       "184298  pandas,matplotlib  avocado dataframe groupby plot i have a datafr...\n",
       "21765              pandas  how to set avocado dataframe multiindex in con...\n",
       "7607                keras  what's the difference between lstm() and lstmc..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = shuffle(data, random_state=20)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "519ada55-04d2-4549-99fe-7dbc33ec2da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'selecting specific rows in df based on 2 columns in python avocado i have data from excel loaded into a avocado dataframe. i now want to select only those rows whose assessment id is the max assessment id per appid and for all the ui seq numbers for that appid.  appid   appname assessment id   ui seq number   question    answer text .    1   appname 2493    11  question    no .    1   appname 13808   11  question    ctry of domicile .    1   appname 13808   11  question    name .    1   appname 35316   11  question    ctry of domicile .        1   appname 35316   11  question    name .    1   appname 35316   11  question    nationality .        1   appname 2493    12  question    corp name .    1   appname 2493    12  question    cr br scr .    1   appname 2493    12  question    inc and assests .    1   appname 2493    12  question    int, ext reg reports .    1   appname 13808   12  question    corp name .    1   appname 35316   12  question    corp name .    1   appname 2493    13  question    no .    1   appname 13808   13  question    no .    1   appname 35316   13  question    no .    1   appname 2493    14  question    no .    1   appname 13808   14  question    firms pos .    1   appname 35316   14  question    firms pos .      and the result would be  appid   appname assessment id   ui seq number   question    answer text .    1   appname 35316   11  question    ctry of domicile .    1   appname 35316   11  question    name .    1   appname 35316   11  question    nationality .    1   appname 35316   12  question    corp name .    1   appname 35316   13  question    no .    1   appname 35316   14  question    firms pos .    '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "358a05ea-44b4-4c8a-88a9-9ff63041e4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_split = [tags.split(',') for tags in data['tags'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e22f21f-7600-46d5-a024-393e9beda84e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pandas', 'matplotlib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_split[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1914bbaa-a5cd-4b88-ad61-2250b071f36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_encoder = MultiLabelBinarizer()\n",
    "tags_encoded = tag_encoder.fit_transform(tags_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5743661e-1249-46ae-8b22-e29cf2646bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tags =len(tags_encoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27e92d47-281a-40a9-9677-c21a5dd37ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5742531-a5e6-4823-aeba-be6cbcadaf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['keras' 'matplotlib' 'pandas' 'scikitlearn' 'tensorflow']\n"
     ]
    }
   ],
   "source": [
    "print(tag_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8a53f72-cb03-4aec-868d-bcae6cecb7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_encoded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "671a3333-c315-4f67-800d-39ef0ee53534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_encoded[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfec959d-938a-4e0b-9d79-e41ae6cde842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 150559\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(data)*.8)\n",
    "print(\"train size: %d\" % train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02505ff1-1dee-4748-bb40-2283fe2e79e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test size: 37640\n"
     ]
    }
   ],
   "source": [
    "print(\"test size: %d\" % (len(data) -train_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03984ac1-44d2-490c-885f-1574dbba51ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tags = tags_encoded[:train_size]\n",
    "test_tags = tags_encoded[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b842af1-835b-4914-b890-569081a163b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 1, 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581de0a7-64a9-4169-9a8d-926ce291d746",
   "metadata": {},
   "source": [
    "# Feature Engineering for our X's (predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70762d7e-75d9-4057-8d5d-7d18c51f028e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocess.py\n",
    "\n",
    "from tensorflow.keras.preprocessing import text\n",
    "\n",
    "class TextPreprocessor(object):\n",
    "    def __init__(self, vocab_size):\n",
    "        self._vocab_size = vocab_size\n",
    "        self._tokenizer = None\n",
    "        \n",
    "    def create_tokenizer(self, text_list):\n",
    "        tokenizer = text.Tokenizer(num_words=self._vocab_size)\n",
    "        tokenizer.fit_on_texts(text_list)\n",
    "        self._tokenizer = tokenizer\n",
    "    \n",
    "    def transform_text(self, text_list):\n",
    "        text_matrix=self._tokenizer.texts_to_matrix(text_list)\n",
    "        return text_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a64b6ca7-c537-4692-a893-8b38a486449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import TextPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ef21359-d7e7-4e47-8f4a-7a76aca8dedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qs = data['text'].values[:train_size]\n",
    "test_qs =data['text'].values[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2dec14a2-7697-4877-bcb7-1268ffcbdbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_qs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b63d25af-3686-4cbc-a3ee-931b6aad54d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "preprocess.TextPreprocessor"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE=400\n",
    "processor = TextPreprocessor(VOCAB_SIZE)\n",
    "type(processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3ce8572-9eae-47be-ba66-77babb4f5193",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.create_tokenizer(train_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e4559a7-8a0d-4e18-9e54-f1849c6cadec",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_train = processor.transform_text(train_qs)\n",
    "body_test = processor.transform_text(test_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b592854-f474-4cbe-b723-41acaba07121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(body_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "07d8aaed-704f-4c59-8557-1443dae0e294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(body_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dbe35615-f79b-4655-b5ee-f6efd1f0f02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./processor_state.pkl', 'wb') as f:\n",
    "    pickle.dump(processor,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe4af2c-1545-46cf-8d1b-78d942260bd0",
   "metadata": {},
   "source": [
    "# Build and train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "83fe4093-935a-480d-a945-a70394025cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocab_size, num_tags):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(50, input_shape=(VOCAB_SIZE,), activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(25, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(num_tags, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "                  \n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5c717b05-5240-4409-ae20-65d50f4c0388",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-18 15:09:21.138579: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-03-18 15:09:21.147647: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-18 15:09:21.147702: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (vm-1a1132b4-6adb-45c9-b1ce-76bd1b8b9bc5): /proc/driver/nvidia/version does not exist\n",
      "2022-03-18 15:09:21.184566: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model =create_model(VOCAB_SIZE, num_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e2f64cd9-b17f-4d6d-a707-cbc06f7245cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 50)                20050     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,455\n",
      "Trainable params: 21,455\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5b522c80-c80e-488f-9f39-1ec7bab36c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-18 15:12:10.876390: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 216804800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1059/1059 [==============================] - 8s 6ms/step - loss: 0.1498 - accuracy: 0.8517 - val_loss: 0.1095 - val_accuracy: 0.8951\n",
      "Epoch 2/5\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.1061 - accuracy: 0.8941 - val_loss: 0.1036 - val_accuracy: 0.8982\n",
      "Epoch 3/5\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1005 - accuracy: 0.8962 - val_loss: 0.1005 - val_accuracy: 0.8982\n",
      "Epoch 4/5\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.0965 - accuracy: 0.8993 - val_loss: 0.1001 - val_accuracy: 0.9016\n",
      "Epoch 5/5\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0934 - accuracy: 0.9025 - val_loss: 0.0990 - val_accuracy: 0.8992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa74c23db90>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(body_train, train_tags, epochs=5, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3cb0ce36-50bb-419f-bb01-7448e2e23e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 68/295 [=====>........................] - ETA: 0s - loss: 0.0974 - accuracy: 0.8997"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-18 15:13:22.127536: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 60224000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295/295 [==============================] - 0s 2ms/step - loss: 0.0996 - accuracy: 0.8975\n",
      "Eval loss/accuracy:[0.09957630932331085, 0.8975026607513428]\n"
     ]
    }
   ],
   "source": [
    "print('Eval loss/accuracy:{}'.format(model.evaluate(body_test, test_tags, batch_size=128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "850089e9-a563-4569-97f1-fd3e82aa5b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('keras_saved_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1ef728eb-a511-4b58-a5bc-ff19ea5cbe7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_prediction2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_prediction2.py\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class CustomModelPrediction(object):\n",
    "    def __init__(self, model, processor):\n",
    "        self._model= model\n",
    "        self._processor = processor\n",
    "    \n",
    "    def predict(self, instances, **kwargs):\n",
    "        preprocessed_data = self._processor.transform_text(instances)\n",
    "        predictions = self._model.predict(preprocessed_data)\n",
    "        return predictions.tolist()\n",
    "    \n",
    "    @classmethod\n",
    "    def from_path(cls, model_dir):\n",
    "        import os\n",
    "        import tensorflow.keras as keras\n",
    "        model = keras.models.load_model(os.path.join(model_dir,'keras_saved_model.h5'))\n",
    "        with open(os.path.join(model_dir, 'processor_state.pkl'), 'rb') as f:\n",
    "                  processor = pickle.load(f)\n",
    "        return cls(model, processor)\n",
    "                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d775cb42-debc-4a61-a46b-31f3f64d4df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_request = [\n",
    "  \"How to preprocess strings in Keras models Lambda layer? I have the problem that the value passed on to the Lambda layer (at compile time) is a placeholder generated by keras (without values). When the model is compiled, the .eval () method throws the error: You must feed a value for placeholder tensor 'input_1' with dtype string and shape [?, 1] def text_preprocess(x): strings = tf.keras.backend.eval(x) vectors = [] for string in strings: vector = string_to_one_hot(string.decode('utf-8')) vectors.append(vector) vectorTensor = tf.constant(np.array(vectors),dtype=tf.float32) return vectorTensor input_text = Input(shape=(1,), dtype=tf.string) embedding = Lambda(text_preprocess)(input_text) dense = Dense(256, activation='relu')(embedding) outputs = Dense(2, activation='softmax')(dense) model = Model(inputs=[input_text], outputs=outputs) model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy']) model.summary() model.save('test.h5') If I pass a string array into the input layer statically, I can compile the model, but I get the same error if I want to convert the model to tflite. #I replaced this line: input_text = Input(shape=(1,), dtype=tf.string) #by this lines: test = tf.constant(['Hello', 'World']) input_text = Input(shape=(1,), dtype=tf.string, tensor=test) #but calling this ... converter = TFLiteConverter.from_keras_model_file('string_test.h5') tfmodel = converter.convert() #... still leads to this error: InvalidArgumentError: You must feed a value for placeholder tensor 'input_3' with dtype string and shape [2] [[{{node input_3}}]] \",\n",
    "  \"Change the bar item name in Pandas I have a test excel file like: df = pd.DataFrame({'name':list('abcdefg'), 'age':[10,20,5,23,58,4,6]}) print (df) name  age 0    a   10 1    b   20 2    c    5 3    d   23 4    e   58 5    f    4 6    g    6 I use Pandas and matplotlib to read and plot it: import pandas as pd import numpy as np import matplotlib.pyplot as plt import os excel_file = 'test.xlsx' df = pd.read_excel(excel_file, sheet_name=0) df.plot(kind='bar') plt.show() the result shows: enter image description here it use index number as item name, how can I change it to the name, which stored in column name?\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4b8aefed-1904-428b-9408-dbeeddfab61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_prediction2 import CustomModelPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "aecae44e-dab5-4a5d-9b6b-64fa0f36cc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = CustomModelPrediction.from_path('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8a76f5c4-8028-4323-83c3-1d186b709414",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=classifier.predict(test_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fc59c13a-1c85-454e-80b6-de5310f84f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9935271739959717,\n",
       " 6.608804170582516e-08,\n",
       " 0.0012646317481994629,\n",
       " 0.0001308917999267578,\n",
       " 0.7115932703018188]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6ac4c63c-8a08-4377-ab74-d4643674b64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels for text-0:\n",
      "keras\n",
      "tensorflow\n",
      "\n",
      "\n",
      "Predicted labels for text-1:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(results)):\n",
    "  print('Predicted labels for text-{}:'.format(i))\n",
    "  for idx, val in enumerate(results[i]):\n",
    "    if val > 0.7:\n",
    "      print(tag_encoder.classes_[idx])\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc46ba0-ef42-420d-b3fc-b495cf51ed38",
   "metadata": {},
   "source": [
    "# Package our Model and deploy it INTO AI PLATFORM!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefcfc82-766e-4ce2-b97c-4005b08584ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "managed-notebooks.m90",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu:latest"
  },
  "kernelspec": {
   "display_name": "TensorFlow 2 (Local)",
   "language": "python",
   "name": "local-tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
